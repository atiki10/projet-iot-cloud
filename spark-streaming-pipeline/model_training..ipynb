{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d1afc7-a874-42f4-9adb-206e6613d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, to_timestamp, unix_timestamp, lag, when, lit, sqrt\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
    "from synapse.ml.isolationforest import IsolationForest\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7554edd-402b-43b6-96ae-0961c50c1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "# *** IMPORTANT: Path to your HISTORICAL data file ***\n",
    "HISTORICAL_DATA_PATH = \"data/smart_logistics_iot_with_battery.csv\"\n",
    "MODELS_DIR = \"models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0486e33-fcdf-42ef-b60e-e2b01225c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ParcelTrainingBatchJob\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.11.4,org.apache.spark:spark-avro_2.12:3.5.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb5f8a4-92ca-4b00-b3f4-51826b20ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Schema (Same as your stream)\n",
    "# --------------------\n",
    "schema = StructType([\n",
    "    StructField(\"Transaction ID\", StringType(), True),\n",
    "    StructField(\"Stage\", StringType(), True),\n",
    "    StructField(\"Entity\", StringType(), True),\n",
    "    StructField(\"Timestamp\", StringType(), True),\n",
    "    StructField(\"RFID ID\", StringType(), True),\n",
    "    StructField(\"GPS Latitude\", DoubleType(), True),\n",
    "    StructField(\"GPS Longitude\", DoubleType(), True),\n",
    "    StructField(\"Temperature\", DoubleType(), True),\n",
    "    StructField(\"Humidity\", DoubleType(), True),\n",
    "    StructField(\"Route ID\", StringType(), True),\n",
    "    StructField(\"Speed\", DoubleType(), True),\n",
    "    StructField(\"Delivery Status\", StringType(), True),\n",
    "    StructField(\"Risk Factor\", StringType(), True),\n",
    "    StructField(\"Delay Time\", StringType(), True),\n",
    "    StructField(\"Cost\", StringType(), True),\n",
    "    StructField(\"Disruption Type\", StringType(), True),\n",
    "    StructField(\"battery_level\", DoubleType(), True),\n",
    "    StructField(\"battery_status\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c158fad4-643b-4371-ba18-08f353c234a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical data from data/smart_logistics_iot_with_battery.csv...\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Load Historical Data\n",
    "# --------------------\n",
    "print(f\"Loading historical data from {HISTORICAL_DATA_PATH}...\")\n",
    "# Switched from .parquet to .csv and added header=True\n",
    "batch_df = spark.read.schema(schema).csv(HISTORICAL_DATA_PATH, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025d34f6-2f72-41f6-8125-7cefaff28ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying feature engineering...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------\n",
    "# Feature Engineering (Same as your stream)\n",
    "# --------------------\n",
    "print(\"Applying feature engineering...\")\n",
    "parsed2 = batch_df.withColumn(\"ts\", to_timestamp(col(\"Timestamp\")))\n",
    "w = Window.partitionBy(\"RFID ID\").orderBy(\"ts\")\n",
    "parsed3 = parsed2.withColumn(\"prev_lat\", lag(\"GPS Latitude\").over(w)) \\\n",
    "    .withColumn(\"prev_lon\", lag(\"GPS Longitude\").over(w)) \\\n",
    "    .withColumn(\"prev_ts\", lag(\"ts\").over(w))\n",
    "\n",
    "parsed4 = parsed3.withColumn(\"time_diff_secs\", (unix_timestamp(col(\"ts\")) - unix_timestamp(col(\"prev_ts\")))) \\\n",
    "    .withColumn(\"lat_diff\", col(\"GPS Latitude\") - col(\"prev_lat\")) \\\n",
    "    .withColumn(\"lon_diff\", col(\"GPS Longitude\") - col(\"prev_lon\")) \\\n",
    "    .withColumn(\"dist_approx\", sqrt(col(\"lat_diff\")**2 + col(\"lon_diff\")**2)) \\\n",
    "    .withColumn(\"speed_calc\", when(col(\"time_diff_secs\") > 0, col(\"dist_approx\") / col(\"time_diff_secs\")).otherwise(col(\"Speed\")))\n",
    "\n",
    "# Final engineered features\n",
    "eng_df = parsed4.withColumn(\"battery_low\", when(col(\"battery_level\") < 20, 1.0).otherwise(0.0)) \\\n",
    "    .withColumn(\"temp_alert\", when((col(\"Temperature\") > 40) | (col(\"Temperature\") < -10), 1.0).otherwise(0.0)) \\\n",
    "    .withColumn(\"delayed_label\", when(col(\"Delay Time\").isNotNull() & (col(\"Delay Time\") != \"0\"), 1).otherwise(0)) \\\n",
    "    .na.fill(0) # Fill NaNs created by lag() and calcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a6e3c1-2298-4f43-8685-c48ab35c1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Model Pipelines (Same definitions)\n",
    "# --------------------\n",
    "feature_cols = [\"GPS Latitude\", \"GPS Longitude\", \"Temperature\", \"Humidity\", \"Speed\", \"dist_approx\", \"speed_calc\", \"time_diff_secs\", \"battery_level\", \"battery_low\", \"temp_alert\"]\n",
    "cat_cols = [\"Delivery Status\", \"Stage\", \"Route ID\", \"battery_status\", \"Risk Factor\", \"Disruption Type\"]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid=\"keep\") for c in cat_cols]\n",
    "assembler_all_features = VectorAssembler(inputCols=feature_cols + [c+\"_idx\" for c in cat_cols], outputCol=\"features_raw\", handleInvalid=\"keep\")\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", withMean=True, withStd=True)\n",
    "\n",
    "# --- RF Pipeline ---\n",
    "rf = RandomForestClassifier(labelCol=\"delayed_label\", featuresCol=\"features\", numTrees=100, maxDepth=8)\n",
    "pipeline_rf = Pipeline(stages=indexers + [assembler_all_features, scaler, rf])\n",
    "\n",
    "# --- K-Means Pipeline ---\n",
    "kmeans_features = VectorAssembler(inputCols=[\"GPS Latitude\", \"GPS Longitude\", \"speed_calc\"], outputCol=\"traj_feats\", handleInvalid=\"keep\")\n",
    "kmeans = KMeans(featuresCol=\"traj_feats\", predictionCol=\"traj_cluster\", k=12, maxIter=20)\n",
    "pipeline_kmeans = Pipeline(stages=[kmeans_features, kmeans])\n",
    "\n",
    "# --- Isolation Forest Pipeline ---\n",
    "# *** FIX 3: Final attempt at correct parameter names ***\n",
    "# Using 'predictionCol' and 'scoreCol'\n",
    "iforest = IsolationForest(\n",
    "    featuresCol=\"features\", \n",
    "    predictionCol=\"anomaly_pred\", \n",
    "    scoreCol=\"anomaly_score\", \n",
    "    contamination=0.05\n",
    ")\n",
    "pipeline_iforest = Pipeline(stages=indexers + [assembler_all_features, scaler, iforest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be06a22-f787-4a0f-a1db-dbb970853406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data for training and testing...\n",
      "\n",
      "--- Training Random Forest Model ---\n",
      "Evaluating RF Model...\n",
      "=====================================\n",
      "RF Model Accuracy: 100.00%\n",
      "RF Model F1 Score: 1.0000\n",
      "=====================================\n",
      "Saving RF Model...\n",
      "\n",
      "--- Training K-Means Model ---\n",
      "Evaluating K-Means Model...\n",
      "=====================================\n",
      "K-Means Silhouette Score: 0.5838 (Closer to 1 is better)\n",
      "=====================================\n",
      "Saving K-Means Model...\n",
      "\n",
      "--- Training Isolation Forest Model ---\n",
      "Evaluating Isolation Forest (on test data)...\n",
      "=====================================\n",
      "Anomaly prediction counts (1 = Anomaly, -1 = Inlier):\n",
      "+------------+-----+\n",
      "|anomaly_pred|count|\n",
      "+------------+-----+\n",
      "|         1.0|   35|\n",
      "|         0.0|  127|\n",
      "+------------+-----+\n",
      "\n",
      "=====================================\n",
      "Saving Isolation Forest Model...\n",
      "\n",
      "All models trained, evaluated, and saved.\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Train, Evaluate, and Save Models\n",
    "# --------------------\n",
    "\n",
    "print(\"Splitting data for training and testing...\")\n",
    "(trainingData, testData) = eng_df.randomSplit([0.8, 0.2], seed=42)\n",
    "trainingData.cache()\n",
    "testData.cache()\n",
    "\n",
    "# --- 1. Random Forest ---\n",
    "print(\"\\n--- Training Random Forest Model ---\")\n",
    "rf_model = pipeline_rf.fit(trainingData)\n",
    "\n",
    "print(\"Evaluating RF Model...\")\n",
    "rf_predictions = rf_model.transform(testData)\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"delayed_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"delayed_label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "accuracy = evaluator_accuracy.evaluate(rf_predictions)\n",
    "f1_score = evaluator_f1.evaluate(rf_predictions)\n",
    "\n",
    "print(f\"=====================================\")\n",
    "print(f\"RF Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"RF Model F1 Score: {f1_score:.4f}\")\n",
    "print(f\"=====================================\")\n",
    "\n",
    "print(\"Saving RF Model...\")\n",
    "rf_model.write().overwrite().save(os.path.join(MODELS_DIR, \"rf_pipeline\"))\n",
    "\n",
    "# --- 2. K-Means ---\n",
    "print(\"\\n--- Training K-Means Model ---\")\n",
    "kmeans_model = pipeline_kmeans.fit(trainingData)\n",
    "\n",
    "print(\"Evaluating K-Means Model...\")\n",
    "kmeans_predictions = kmeans_model.transform(testData)\n",
    "kmeans_evaluator = ClusteringEvaluator(featuresCol=\"traj_feats\", predictionCol=\"traj_cluster\", metricName=\"silhouette\")\n",
    "silhouette_score = kmeans_evaluator.evaluate(kmeans_predictions)\n",
    "\n",
    "print(f\"=====================================\")\n",
    "print(f\"K-Means Silhouette Score: {silhouette_score:.4f} (Closer to 1 is better)\")\n",
    "print(f\"=====================================\")\n",
    "\n",
    "print(\"Saving K-Means Model...\")\n",
    "kmeans_model.write().overwrite().save(os.path.join(MODELS_DIR, \"kmeans_pipeline\"))\n",
    "\n",
    "# --- 3. Isolation Forest ---\n",
    "print(\"\\n--- Training Isolation Forest Model ---\")\n",
    "iforest_model = pipeline_iforest.fit(trainingData)\n",
    "\n",
    "print(\"Evaluating Isolation Forest (on test data)...\")\n",
    "iforest_predictions = iforest_model.transform(testData)\n",
    "print(f\"=====================================\")\n",
    "print(\"Anomaly prediction counts (1 = Anomaly, 0 = Inlier):\")\n",
    "# Note: SynapseML IsolationForest uses 1 (anomaly) and 0 (inlier)\n",
    "iforest_predictions.groupBy(\"anomaly_pred\").count().show()\n",
    "print(f\"=====================================\")\n",
    "\n",
    "print(\"Saving Isolation Forest Model...\")\n",
    "iforest_model.write().overwrite().save(os.path.join(MODELS_DIR, \"iforest_pipeline\"))\n",
    "\n",
    "print(\"\\nAll models trained, evaluated, and saved.\")\n",
    "spark.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a78e3-86e7-4760-bb06-fea2117f5d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc8d43-5aaa-4a80-82de-0ea2ab71d5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
